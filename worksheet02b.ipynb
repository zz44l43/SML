{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90051 Workshop 2\n",
    "## Part B: Bayesian inference\n",
    "\n",
    "***\n",
    "\n",
    "In this part of the workshop, we'll develop some intuition for priors and posteriors, which are crucial to Bayesian inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import bernoulli, beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. A lucky find\n",
    "\n",
    "On the way to class, you discover an unusual coin on the ground.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/68/1_2_penny_Middlesex_DukeYork_1795_1ar85_%288737903267%29.jpg\" alt=\"Coin\" width=\"350\"/>\n",
    "\n",
    "As a dedicated student in statistical ML, you're interested in determining whether the coin is biased. \n",
    "More specifically, you want to estimate the probability $\\theta$ that the coin will land heads-up when you toss it.\n",
    "\n",
    "You can use the function below to simulate a coin toss: it returns `1` for heads and `0` for tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toss_coin():\n",
    "    if bernoulli.rvs(p = (int.from_bytes(\"coin\".encode(), 'little') % 10000)/10000):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prior belief\n",
    "Before you even toss the coin, you notice that the heads side appears to have more mass. \n",
    "Thus, your _prior belief_ is that $\\theta$ is slightly biased away from 0.5 towards 0â€”i.e. you expect tails are more likely.\n",
    "\n",
    "To quantify this prior belief, we assume that the prior distribution for $\\theta$ is $\\mathrm{Beta}(a,b)$, for some choice of the hyperparameters $a, b > 0$. \n",
    "(See [link](https://en.wikipedia.org/wiki/Beta_distribution) for info about the Beta distribution.)\n",
    "The prior probability density function for $\\theta$ is therefore given by:\n",
    "\n",
    "$$ p(\\theta) = \\frac{1}{B(a,b)} \\theta^{a-1} (1 - \\theta)^{b-1} $$\n",
    "where $B(a,b)$ is a special function called the _Beta function_.\n",
    "\n",
    "Select appropriate values for $a$ and $b$ by looking at the plot of $p(\\theta)$ below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ... # fill in\n",
    "b = ... # fill in\n",
    "theta = np.linspace(0, 1, 1000)\n",
    "plt.plot(theta, beta.pdf(theta, a, b), 'b-', lw=1)\n",
    "plt.xlabel(r'$\\theta$')\n",
    "plt.ylabel(r'$p(\\theta)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Posterior updates\n",
    "Now toss the coin once and denote the outcome by $x_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = toss_coin()\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can update our belief about $\\theta$, based on this new evidence $x_1$.\n",
    "To do this we apply Bayes' rule to compute the posterior for $\\theta$:\n",
    "$$ p(\\theta | x_1) = \\frac{p(x_1 | \\theta) \\, p(\\theta)}{p(x_1)} \\propto p(x_1 | \\theta) \\, p(\\theta)$$\n",
    "where $p(\\theta)$ is the prior given above and \n",
    "$$ p(x_1 | \\theta) = \\theta^{x_1} (1 - \\theta)^{1 - x_1} $$\n",
    "is the likelihood.\n",
    "\n",
    "***\n",
    "**Exercise:** Show (on paper) that\n",
    "$$ p(\\theta | x_1) \\propto \\theta^{x_1 + a - 1} (1 - \\theta)^{(1 - x_1) + b - 1} $$\n",
    "which implies that $\\theta | x_1 \\sim \\mathrm{Beta}[x_1 + a - 1, (1 - x_1) + b - 1]$.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toss the coin a second time, denoting the outcome by $x_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = toss_coin()\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we want to update our belief about $\\theta$ based on the new information $x_2$. \n",
    "We take the previous posterior $p(\\theta|x_1)$ as the new prior and apply Bayes' rule:\n",
    "$$ p(\\theta | x_1, x_2) \\propto p(x_2 | \\theta) p(\\theta | x_1)$$\n",
    "\\[Note: We assume the tosses are independent, otherwise the likelihood for $x_2$ would depend on $x_1$.\\] \n",
    "This gives $\\theta | x_1, x_2 \\sim \\mathrm{Beta}[x_1 + x_2 + a - 1, (2 - x_1 - x_2) + b - 1]$.\n",
    "\n",
    "***\n",
    "**Exercise:** Show that for $n$ coin tosses, the posterior is $\\theta | x_1, \\ldots, x_n \\sim \\operatorname{Beta}[n_H + a - 1, n - n_H + b - 1]$ where $n_H = \\sum_{i = 1}^{n} x_i$ is the number of heads observed.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. MAP estimator and MLE estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior $\\theta|x_1, \\ldots, x_n$ contains all the information we know about $\\theta$ after observing $n$ coin tosses.\n",
    "One way of obtaining a point estimate of $\\theta$ from the posterior, is to take the value with the maximum a posteriori probability (MAP):\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\hat{\\theta}_{MAP} &= \\arg \\max_{\\theta} p(\\theta|x_1, \\ldots, x_n) \\\\\n",
    "        & = \\frac{n_H + a - 1}{n + a + b - 2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In general, the MAP estimator gives a different result to the maximum likelihood estimator (MLE) for $\\theta$:\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\hat{\\theta}_{MLE} &=\\arg \\max_{\\theta} p(x_1, \\ldots, x_n|\\theta) \\\\\n",
    "        & = \\frac{n_H}{n}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "***\n",
    "**Exercise:** Derive the above results for $\\hat{\\theta}_{MAP}$ and  $\\hat{\\theta}_{MLE}$.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Convergence of the estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now toss the coin an additional 48 times (so that $n = 50$), recording $\\hat{\\theta}_{MLE}$ and $\\hat{\\theta}_{MAP}$ after each toss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tosses = 48\n",
    "num_tosses = 2 + extra_tosses\n",
    "num_heads = 0\n",
    "theta_map = np.zeros(num_tosses)\n",
    "theta_mle = np.zeros(num_tosses)\n",
    "for i in range(0, num_tosses):\n",
    "    if i == 0: \n",
    "        num_heads += x1 \n",
    "    elif i == 1:\n",
    "        num_heads += x2\n",
    "    else:\n",
    "        num_heads += toss_coin()\n",
    "    theta_map[i] = ... # fill in\n",
    "    theta_mle[i] = ... # fill in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the results below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(theta_map, label = \"MAP\")\n",
    "plt.plot(theta_mle, label = \"MLE\")\n",
    "plt.xlabel('Number of draws')\n",
    "plt.ylabel(r'$\\hat{\\theta}$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:** \n",
    "\n",
    "1. Is the coin biased?\n",
    "1. Do the MAP and MLE estimates converge to the same value for $\\theta$?\n",
    "1. What happens if you set $a = 1; b = 1$?\n",
    "1. How does the posterior distribution for $\\theta$ compare to the prior plotted above? (Use the code block below to plot the posterior.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(theta, beta.pdf(theta, a + num_heads, b + num_tosses - num_heads), 'b-', lw=1)\n",
    "plt.xlabel(r'$\\theta$')\n",
    "plt.ylabel(r'$p(\\theta|x_1, \\ldots, x_n)$')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
